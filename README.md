# SI-Attack: Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency

The core code of Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency. 

Our paper can be viewed in [Here](https://arxiv.org/abs/2501.04931)

The evaluation result on GPT-4o-05-13 can be found in [Here](https://drive.google.com/drive/folders/1F2VdH_mPblwe2_PZCfbsfgqAsjy5OMR4?usp=drive_link)

