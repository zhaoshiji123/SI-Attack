# SI-Attack: Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency

The core code of Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency. 

Our paper can be viewed in [Here](https://arxiv.org/abs/2501.04931)

The evaluation result on GPT-4o-05-13 can be found in [Here](https://drive.google.com/drive/folders/1F2VdH_mPblwe2_PZCfbsfgqAsjy5OMR4?usp=drive_link)

The entire instruction will be released soon.


### Citation

```bash
@inproceedings{Zhao2025Jailbreaking,
title={Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency},
author={Shiji Zhao and Ranjie Duan and Fengxiang Wang and Chi Chen and Caixin Kang and Shouwei Ruan and Jialing Tao and YueFeng Chen and Hui Xue and Xingxing Wei},
year={2022},
}
```

